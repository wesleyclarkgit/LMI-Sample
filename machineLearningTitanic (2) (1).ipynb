{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Survival of the Titanic Passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Source: [https://ww2.amstat.org/publications/jse/v3n3/datasets.dawson.html](https://ww2.amstat.org/publications/jse/v3n3/datasets.dawson.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Load Libraries](#load_libraries)\n",
    "- [Access data](#access_data)\n",
    "- [Split Data into Training and Test set](#training_test)\n",
    "- [Build Logistic Regression Model](#build_model)\n",
    "- [Predict for Test data](#test_data)\n",
    "- [Evaluate the Model](#evaluate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load_libraries\"></a>\n",
    "## Load Libraries\n",
    "\n",
    "The Spark and Python libraries that you need are preinstalled in the notebook environment and only need to be loaded.\n",
    "\n",
    "Run the following cell to load the libraries you will work with in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PySpark Machine Learning Library\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row, SQLContext\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Library for confusion matrix, precision, test error\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# Library For Area under ROC curve and Area under precision-recall curve\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "# Assign resources to the application\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data will be loaded into an array.\n",
    "# This is the summary of the data structure, including the column position and name.\n",
    "# The first filed starts from position 0. \n",
    "\n",
    "# 0 Interaction ID - This is a VarChar identifaction that serves to make each entry unique and accesible\n",
    "# 1 Article_URL - This is the URL where the text was taken from\n",
    "# 2 Content - The text of each tweet\n",
    "# 3 Time - timestamp of content\n",
    "# 4 Relevant - Description of whether or not the tweet was about the subject matter\n",
    "# 5 Sentiment - 5 different sentiments expressed as to the persons feelings\n",
    "# Gender - male/female description of subject\n",
    "# Dizziness - yes/no description of whether or not dizziness occurred\n",
    "# Convulsions - yes/no description of whether or not convulsions were present in the patient\n",
    "# HEART PALPITATIONS - yes/no description of whether or not heart palpitations were present\n",
    "# SHORTNESS OF BREATHE - yes/no description of the whether or not the person experienced breathing difficulties\n",
    "# HEADACHES - yes/no description of headaches being present \n",
    "# DRUG EFFECT DECREASED - yes/no description of whether or not the effect of claritin decreased over time\n",
    "# ALLERGIES WORSE AFTER TAKING DRUG - yes/no description of symptoms getting worse after medication\n",
    "# BAD INTERACTION BETWEEN CLARITIN AND ANOTHER DRUG. - yes/no description of synergistic reaction with other drug\n",
    "# NAUSEA (MADE THE PERSON NAUSEOUS) - yes/no description of whether the person was nauseous or not\n",
    "# CAUSED INSOMNIA (THE PERSON WASNT ABLE TO SLEEP) - yes/no description of whether the person was able to sleep\n",
    "\n",
    "# Label is a target variable. PersonInfo is a list of independent variables besides unique identifier\n",
    "\n",
    "LabeledDocument = Row(\"Interaction ID\", \"Article URL\", \"Content\", \" Time\", \"Relevant\", \"Sentiment\", \"Gender\", \"Dizziness\", \"Convulsions\", \"Heart Palpitations\", \"Shortness of Breathe\", \"Headaches\", \"Drug Effect Decreased\", \"Allergies Worse After Taking the Drug\", \"Bad Interaction Between Claritin and Another Drug\", \"Nausea\", \"Caused Insomnia\")\n",
    "\n",
    "# Define a function that parses the raw CSV file and returns an object of type LabeledDocument\n",
    "\n",
    "def parseDocument(line):\n",
    "    values = [str(x) for x in line.split(',')] \n",
    "    if (values[4]>'0'):\n",
    "      Survived = 1.0\n",
    "    else:\n",
    "      Survived = 0.0\n",
    "        \n",
    "    textValue = str(values[1]) + \" \" + str(values[2])+\" \" + str(values[3])\n",
    "    return LabeledDocument(values[5], textValue, Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"access_data\"></a>\n",
    "## Access Data\n",
    "Before you can access data in the data file in the Object Storage, you must setup the Spark configuration with your Object Storage credentials. \n",
    "\n",
    "To do this, click on the cell below and select the **Insert to code > Insert Spark Session DataFrame** function from the Files tab below the data file you want to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">The following code contains the credentials for a file in your IBM Cloud Object Storage. Delete the code starting from `from pyspark.sql import SparkSession` line before you run the cell.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Object Storage Credentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the data into a `Spark RDD` and output the number of rows and first 5 rows.\n",
    "Each project you create has a bucket in your object storage. You can get the bucket name from the project Settings page. Change the string `BUCKET` to the bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(cos.url('Titanic.csv', 'BUCKET'))\n",
    "print \"Total records in the data set:\", data.count()\n",
    "print \"The first 5 rows\"\n",
    "data.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crate DataFrame from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data into a ataframe, parse it using the function above\n",
    "documents = data.filter(lambda s: \"Name\" not in s).map(parseDocument)\n",
    "TitanicData = documents.toDF() # ToDataFrame\n",
    "print \"Number of records: \" + str(TitanicData.count())\n",
    "print \"First 5 records: \"\n",
    "TitanicData.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"training_test\"></a>\n",
    "## Split Data into Training and Test set\n",
    "\n",
    "We divide the data into training and test set.  The training set is used to build the model to be used on future data, and the test set is used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide the data into training and test set\n",
    "(train, test) = TitanicData.randomSplit([0.8, 0.2])\n",
    "print \"Number of records in the training set: \" + str(train.count())\n",
    "print \"Number of records in the test set: \" + str(test.count())\n",
    "# Output first 20 records in the training set\n",
    "print \"First 20 records in the training set: \"\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build_model\"></a>\n",
    "## Build Logistic Regression Model\n",
    "\n",
    "We use the Pipeline of SparkML to build the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up Logistic Regression using Pipeline of SparkML\n",
    "tokenizer = Tokenizer(inputCol=\"PersonInfo\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set up Logistic Regression Model\n",
    "# the stages are executed in order\n",
    "model = pipeline.fit(train)\n",
    "#[stage.coefficients for stage in model.stages if hasattr(stage, \"coefficients\")]\n",
    "# model.stages[2].intercept\n",
    "model.stages[2].coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_data\"></a>\n",
    "## Predict for Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on test documents and print columns of interest\n",
    "prediction = model.transform(test)\n",
    "selected = prediction.select(\"PersonInfo\", \"prediction\", \"probability\")\n",
    "for row in selected.collect():\n",
    "    print row\n",
    "#for row in prediction.collect():\n",
    "#    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tabulate the predicted outcome\n",
    "prediction.select(\"prediction\").groupBy(\"prediction\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tabulate the actual outcome\n",
    "prediction.select(\"label\").groupBy(\"label\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This table shows:\n",
    "# 1. The number of survived passengers predicted as survived\n",
    "# 2. The number of survived passengers predicted as not survived\n",
    "# 3. The number of not survived passengers predicted as survived\n",
    "# 4. The number of not survived passengers predicted as not survived\n",
    "\n",
    "prediction.crosstab('label', 'prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate_model\"></a>\n",
    "## Evaluate the Model\n",
    "\n",
    "We evaluate the model on a training set and on a test set.  The purpose is to measure the model's predictive accuracy, including the accuracy for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the Logistic Regression model on a training set\n",
    "# Select (prediction, true label) and compute test error\n",
    "pred_lr=model.transform(train).select(\"prediction\", \"label\")\n",
    "eval_lr=MulticlassClassificationEvaluator (\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_lr=eval_lr.evaluate(pred_lr)\n",
    "# create RDD\n",
    "predictionAndLabels_lr=pred_lr.rdd\n",
    "metrics_lr=MulticlassMetrics(predictionAndLabels_lr)\n",
    "precision_lr=metrics_lr.precision(1.0)\n",
    "recall_lr=metrics_lr.recall(1.0)\n",
    "f1Measure_lr = metrics_lr.fMeasure(1.0, 1.0)\n",
    "print(\"F1 Measure = %s\" % f1Measure_lr)\n",
    "print (\"Test Accuracy = %s\" %accuracy_lr)\n",
    "print (\"Test Error = %s\" % (1-accuracy_lr))\n",
    "print (\"Precision = %s\" %precision_lr)\n",
    "print (\"Recall = %s\" %recall_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the Logistic Regression model on a test set\n",
    "# Select (prediction, true label) and compute test error\n",
    "pred_lr=model.transform(test).select(\"prediction\", \"label\")\n",
    "eval_lr=MulticlassClassificationEvaluator (\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_lr=eval_lr.evaluate(pred_lr)\n",
    "# create RDD\n",
    "predictionAndLabels_lr=pred_lr.rdd\n",
    "metrics_lr=MulticlassMetrics(predictionAndLabels_lr)\n",
    "precision_lr=metrics_lr.precision(1.0)\n",
    "recall_lr=metrics_lr.recall(1.0)\n",
    "f1Measure_lr = metrics_lr.fMeasure(1.0, 1.0)\n",
    "print(\"F1 Measure = %s\" % f1Measure_lr)\n",
    "print (\"Test Accuracy = %s\" %accuracy_lr)\n",
    "print (\"Test Error = %s\" % (1-accuracy_lr))\n",
    "print (\"Precision = %s\" %precision_lr)\n",
    "print (\"Recall = %s\" %recall_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_lr=BinaryClassificationMetrics(predictionAndLabels_lr)\n",
    "\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % bin_lr.areaUnderPR)\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under ROC = %s\" % bin_lr.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "machineLearningHAVCBluemix.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
